{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5332,"status":"ok","timestamp":1638466612167,"user":{"displayName":"Ikram Ullah Baig","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhL73f-0emzaLyvje4hCw_28-Mvzl2zNYtMmB7brg=s64","userId":"15580659241174770721"},"user_tz":-300},"id":"TfFTmE9_M4da","outputId":"be5bf53a-a513-4d78-8bec-4311e04baa5d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 32)]              0         \n","                                                                 \n"," dense (Dense)               (None, 32768)             1081344   \n","                                                                 \n"," leaky_re_lu (LeakyReLU)     (None, 32768)             0         \n","                                                                 \n"," reshape (Reshape)           (None, 16, 16, 128)       0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 16, 16, 256)       819456    \n","                                                                 \n"," leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 256)       0         \n","                                                                 \n"," conv2d_transpose (Conv2DTra  (None, 32, 32, 256)      1048832   \n"," nspose)                                                         \n","                                                                 \n"," leaky_re_lu_2 (LeakyReLU)   (None, 32, 32, 256)       0         \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 32, 32, 256)       1638656   \n","                                                                 \n"," leaky_re_lu_3 (LeakyReLU)   (None, 32, 32, 256)       0         \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 32, 32, 256)       1638656   \n","                                                                 \n"," leaky_re_lu_4 (LeakyReLU)   (None, 32, 32, 256)       0         \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 32, 32, 3)         37635     \n","                                                                 \n","=================================================================\n","Total params: 6,264,579\n","Trainable params: 6,264,579\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["from tensorflow import keras\n","from keras import layers\n","import numpy as np\n","\n","latent_dim = 32\n","height = 32\n","width = 32\n","channels = 3\n","\n","generator_input = keras.Input(shape=(latent_dim,))\n","\n","x = layers.Dense(128 * 16 * 16)(generator_input)\n","x = layers.LeakyReLU()(x)\n","x = layers.Reshape((16, 16, 128))(x)\n","\n","x = layers.Conv2D(256, 5, padding='same')(x)\n","x = layers.LeakyReLU()(x)\n","\n","x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n","x = layers.LeakyReLU()(x)\n","\n","x = layers.Conv2D(256, 5, padding='same')(x)\n","x = layers.LeakyReLU()(x)\n","x = layers.Conv2D(256, 5, padding='same')(x)\n","x = layers.LeakyReLU()(x)\n","\n","x = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\n","generator = keras.models.Model(generator_input, x)                   #3\n","generator.summary()\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1638466612170,"user":{"displayName":"Ikram Ullah Baig","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhL73f-0emzaLyvje4hCw_28-Mvzl2zNYtMmB7brg=s64","userId":"15580659241174770721"},"user_tz":-300},"id":"yuG5dRyPNNhw","outputId":"6ba93fe8-61b0-435d-eefe-0737e6546ca7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 30, 30, 128)       3584      \n","                                                                 \n"," leaky_re_lu_5 (LeakyReLU)   (None, 30, 30, 128)       0         \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 14, 14, 128)       262272    \n","                                                                 \n"," leaky_re_lu_6 (LeakyReLU)   (None, 14, 14, 128)       0         \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 6, 6, 128)         262272    \n","                                                                 \n"," leaky_re_lu_7 (LeakyReLU)   (None, 6, 6, 128)         0         \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 2, 2, 128)         262272    \n","                                                                 \n"," leaky_re_lu_8 (LeakyReLU)   (None, 2, 2, 128)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 512)               0         \n","                                                                 \n"," dropout (Dropout)           (None, 512)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 513       \n","                                                                 \n","=================================================================\n","Total params: 790,913\n","Trainable params: 790,913\n","Non-trainable params: 0\n","_________________________________________________________________\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(RMSprop, self).__init__(name, **kwargs)\n"]}],"source":["discriminator_input = layers.Input(shape=(height, width, channels))\n","x = layers.Conv2D(128, 3)(discriminator_input)\n","x = layers.LeakyReLU()(x)\n","x = layers.Conv2D(128, 4, strides=2)(x)\n","x = layers.LeakyReLU()(x)\n","x = layers.Conv2D(128, 4, strides=2)(x)\n","x = layers.LeakyReLU()(x)\n","x = layers.Conv2D(128, 4, strides=2)(x)\n","x = layers.LeakyReLU()(x)\n","x = layers.Flatten()(x)\n","\n","x = layers.Dropout(0.4)(x)\n","\n","x = layers.Dense(1, activation='sigmoid')(x)\n","\n","discriminator = keras.models.Model(discriminator_input, x)\n","discriminator.summary()\n","\n","discriminator_optimizer = keras.optimizers.RMSprop(\n","    lr=0.0008,\n","    clipvalue=1.0,\n","    decay=1e-8)\n","discriminator.compile(optimizer=discriminator_optimizer,\n","                     loss='binary_crossentropy')\n","\t\t\t\t"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1638466612171,"user":{"displayName":"Ikram Ullah Baig","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhL73f-0emzaLyvje4hCw_28-Mvzl2zNYtMmB7brg=s64","userId":"15580659241174770721"},"user_tz":-300},"id":"Ab8dkncENbJt","outputId":"1aacfe33-3779-4bc1-d633-881ec5c7f4a3"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(RMSprop, self).__init__(name, **kwargs)\n"]}],"source":["discriminator.trainable = False\n","\n","gan_input = keras.Input(shape=(latent_dim,))\n","gan_output = discriminator(generator(gan_input))\n","gan = keras.models.Model(gan_input, gan_output)\n","\n","gan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\n","gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"P-dux3tCNdwN"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 2s 0us/step\n","170508288/170498071 [==============================] - 2s 0us/step\n","discriminator loss: 0.6850689649581909\n","adversarial loss: 0.6665905714035034\n","discriminator loss: 0.595664381980896\n","adversarial loss: 1.378741979598999\n","discriminator loss: 0.7039440274238586\n","adversarial loss: 0.8072716593742371\n","discriminator loss: 0.6970177888870239\n","adversarial loss: 0.7447299957275391\n","discriminator loss: 0.715827226638794\n","adversarial loss: 0.7507342100143433\n","discriminator loss: 0.6977410316467285\n","adversarial loss: 0.7512675523757935\n","discriminator loss: 0.6829900741577148\n","adversarial loss: 0.7420787811279297\n","discriminator loss: 0.6921085119247437\n","adversarial loss: 0.7687432765960693\n","discriminator loss: 0.7037160992622375\n","adversarial loss: 0.7575413584709167\n","discriminator loss: 0.7025337219238281\n","adversarial loss: 0.7420147061347961\n","discriminator loss: 0.6959435939788818\n","adversarial loss: 1.16765558719635\n","discriminator loss: 0.6977609992027283\n","adversarial loss: 0.725793719291687\n","discriminator loss: 0.6906071901321411\n","adversarial loss: 0.725143551826477\n","discriminator loss: 0.6935438513755798\n","adversarial loss: 0.7526330351829529\n","discriminator loss: 0.6922513246536255\n","adversarial loss: 0.7456271648406982\n","discriminator loss: 0.6858736276626587\n","adversarial loss: 0.7335284948348999\n","discriminator loss: 0.6958945989608765\n","adversarial loss: 0.7775443196296692\n","discriminator loss: 0.6927777528762817\n","adversarial loss: 0.7673937082290649\n","discriminator loss: 0.6978245377540588\n","adversarial loss: 0.7713061571121216\n","discriminator loss: 0.6885852217674255\n","adversarial loss: 0.7058970332145691\n","discriminator loss: 0.689651370048523\n","adversarial loss: 0.7758336067199707\n","discriminator loss: 0.6996464729309082\n","adversarial loss: 0.7628438472747803\n","discriminator loss: 0.6933183073997498\n","adversarial loss: 0.7127352356910706\n","discriminator loss: 0.6732171773910522\n","adversarial loss: 0.7348321676254272\n","discriminator loss: 0.695523202419281\n","adversarial loss: 0.7501791715621948\n","discriminator loss: 0.678682267665863\n","adversarial loss: 0.7500487565994263\n","discriminator loss: 0.6830493211746216\n","adversarial loss: 0.7332202792167664\n","discriminator loss: 0.6928068995475769\n","adversarial loss: 0.7402331233024597\n","discriminator loss: 0.694169819355011\n","adversarial loss: 0.7611449956893921\n","discriminator loss: 0.691502034664154\n","adversarial loss: 0.7546080350875854\n","discriminator loss: 0.7052392363548279\n","adversarial loss: 0.7274786829948425\n","discriminator loss: 0.6871969103813171\n","adversarial loss: 0.7443849444389343\n","discriminator loss: 0.7073691487312317\n","adversarial loss: 0.7568331956863403\n","discriminator loss: 0.7010877132415771\n","adversarial loss: 0.7355062365531921\n","discriminator loss: 0.7006136178970337\n","adversarial loss: 0.7419120669364929\n","discriminator loss: 0.6944049000740051\n","adversarial loss: 0.7171328663825989\n","discriminator loss: 0.6735237240791321\n","adversarial loss: 0.7159513235092163\n","discriminator loss: 0.7073748707771301\n","adversarial loss: 0.7497285604476929\n","discriminator loss: 0.7013119459152222\n","adversarial loss: 0.8315328359603882\n","discriminator loss: 0.6897913813591003\n","adversarial loss: 0.7334340810775757\n","discriminator loss: 0.696313202381134\n","adversarial loss: 0.6688697934150696\n","discriminator loss: 0.7021878957748413\n","adversarial loss: 0.7132474184036255\n","discriminator loss: 0.6830949783325195\n","adversarial loss: 0.7487046122550964\n","discriminator loss: 0.7272974848747253\n","adversarial loss: 0.8303197026252747\n","discriminator loss: 0.6968084573745728\n","adversarial loss: 0.7671670317649841\n","discriminator loss: 0.6894236207008362\n","adversarial loss: 0.7464898228645325\n","discriminator loss: 0.7048962712287903\n","adversarial loss: 0.7471832036972046\n","discriminator loss: 0.7006900906562805\n","adversarial loss: 0.7613345384597778\n","discriminator loss: 0.7021315693855286\n","adversarial loss: 0.8157991170883179\n","discriminator loss: 0.7511921525001526\n","adversarial loss: 0.7140275239944458\n","discriminator loss: 0.6808665990829468\n","adversarial loss: 0.682977020740509\n","discriminator loss: 0.701728343963623\n","adversarial loss: 0.7350620031356812\n","discriminator loss: 0.6787876486778259\n","adversarial loss: 0.7570561170578003\n","discriminator loss: 0.6925255656242371\n","adversarial loss: 0.7458174824714661\n","discriminator loss: 0.7214547395706177\n","adversarial loss: 0.7189427614212036\n","discriminator loss: 0.6890865564346313\n","adversarial loss: 0.754979133605957\n","discriminator loss: 0.7038337588310242\n","adversarial loss: 0.7510753870010376\n","discriminator loss: 0.6915380358695984\n","adversarial loss: 1.097329020500183\n","discriminator loss: 0.7034685015678406\n","adversarial loss: 0.7603644132614136\n","discriminator loss: 0.6876348257064819\n","adversarial loss: 0.7403534650802612\n","discriminator loss: 0.6991007924079895\n","adversarial loss: 0.7323590517044067\n","discriminator loss: 0.7127355933189392\n","adversarial loss: 0.7408215403556824\n","discriminator loss: 0.6989356875419617\n","adversarial loss: 0.7214670181274414\n","discriminator loss: 0.8081805109977722\n","adversarial loss: 0.7714461088180542\n","discriminator loss: 0.7149969339370728\n","adversarial loss: 0.7555280327796936\n","discriminator loss: 0.691909670829773\n","adversarial loss: 0.7688186764717102\n","discriminator loss: 0.6923461556434631\n","adversarial loss: 0.7572817802429199\n","discriminator loss: 0.6987802386283875\n","adversarial loss: 0.739161491394043\n","discriminator loss: 0.6842150688171387\n","adversarial loss: 0.7907583713531494\n","discriminator loss: 0.6892210841178894\n","adversarial loss: 0.7499707937240601\n","discriminator loss: 0.6928585767745972\n","adversarial loss: 0.7684072852134705\n","discriminator loss: 0.703923761844635\n","adversarial loss: 0.8368029594421387\n","discriminator loss: 0.6890023946762085\n","adversarial loss: 0.8047021627426147\n","discriminator loss: 0.6943863034248352\n","adversarial loss: 0.7506548166275024\n","discriminator loss: 0.6966517567634583\n","adversarial loss: 0.8282822370529175\n","discriminator loss: 0.686416506767273\n","adversarial loss: 0.7612099647521973\n","discriminator loss: 0.7015434503555298\n","adversarial loss: 0.7998549938201904\n","discriminator loss: 0.679138720035553\n","adversarial loss: 0.667316734790802\n","discriminator loss: 0.702831506729126\n","adversarial loss: 0.7314899563789368\n","discriminator loss: 0.6926308870315552\n","adversarial loss: 0.7625875473022461\n","discriminator loss: 0.6908207535743713\n","adversarial loss: 0.778631329536438\n","discriminator loss: 0.6937668919563293\n","adversarial loss: 0.7878099679946899\n","discriminator loss: 0.6959766745567322\n","adversarial loss: 0.3769729733467102\n","discriminator loss: 0.68949294090271\n","adversarial loss: 0.7623314261436462\n","discriminator loss: 0.6904211044311523\n","adversarial loss: 0.7340670824050903\n","discriminator loss: 0.739976704120636\n","adversarial loss: 0.7202265858650208\n","discriminator loss: 0.6947393417358398\n","adversarial loss: 0.7669774293899536\n","discriminator loss: 0.6917482614517212\n","adversarial loss: 0.8495623469352722\n","discriminator loss: 0.6892269849777222\n","adversarial loss: 1.0394301414489746\n","discriminator loss: 0.6772323846817017\n","adversarial loss: 0.719973087310791\n","discriminator loss: 0.6701986193656921\n","adversarial loss: 0.8079797029495239\n","discriminator loss: 0.6986474394798279\n","adversarial loss: 1.0328648090362549\n","discriminator loss: 0.6975950598716736\n","adversarial loss: 0.7948709726333618\n","discriminator loss: 0.7399116158485413\n","adversarial loss: 0.7158734202384949\n","discriminator loss: 0.6902896165847778\n","adversarial loss: 0.6880759000778198\n","discriminator loss: 0.6812361478805542\n","adversarial loss: 0.7844017148017883\n","discriminator loss: 0.6720105409622192\n","adversarial loss: 0.7369524240493774\n","discriminator loss: 0.6871224045753479\n","adversarial loss: 0.7785787582397461\n","discriminator loss: 0.6745458841323853\n","adversarial loss: 0.8168954849243164\n","discriminator loss: 0.7009038925170898\n","adversarial loss: 0.7485858798027039\n"]}],"source":["import os\n","from keras.preprocessing import image\n","\n","(x_train, y_train), (_, _) = keras.datasets.cifar10.load_data()\n","\n","x_train = x_train[y_train.flatten() == 6]\n","\n","x_train = x_train.reshape(\n","    (x_train.shape[0],) +\n","    (height, width, channels)).astype('float32') / 255.\n","\n","iterations = 10000\n","batch_size = 20\n","save_dir = '/content/my_dir'\n","\n","start = 0\n","for step in range(iterations):\n","    random_latent_vectors = np.random.normal(size=(batch_size,\n","                                            latent_dim))\n","\n","    generated_images = generator.predict(random_latent_vectors)\n","\n","    stop = start + batch_size\n","    real_images = x_train[start: stop]\n","    combined_images = np.concatenate([generated_images, real_images])\n","\n","    labels = np.concatenate([np.ones((batch_size, 1)),\n","                             np.zeros((batch_size, 1))])\n","    labels += 0.05 * np.random.random(labels.shape)\n","\n","    d_loss = discriminator.train_on_batch(combined_images, labels)\n","\n","    random_latent_vectors = np.random.normal(size=(batch_size,\n","                                            latent_dim))\n","\n","    misleading_targets = np.zeros((batch_size, 1))\n","\n","    a_loss = gan.train_on_batch(random_latent_vectors,\n","                                misleading_targets)\n","\n","    start += batch_size\n","    if start \u003e len(x_train) - batch_size:\n","      start = 0\n","    if step % 100 == 0:\n","        gan.save_weights('gan.h5')\n","\n","        print('discriminator loss:', d_loss)\n","        print('adversarial loss:', a_loss)\n","\n","        img = image.array_to_img(generated_images[0] * 255., scale=False)\n","        img.save(os.path.join(save_dir,\n","                      'generated_frog' + str(step) + '.png'))\n","\n","        img = image.array_to_img(real_images[0] * 255., scale=False)\n","        img.save(os.path.join(save_dir,\n","                      'real_frog' + str(step) + '.png'))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f1PNo-QXNnCB"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyO1gVyyDZFdAER21rO7cGY/","name":"GANs 1st.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}